\renewcommand{\O}{\mathcal{O}}

% a brief report explaining the design and implementation of your algorithms, as well
% as a set of comprehensive experimental results, clearly analyzed. The design and
% implementation explanations should not exceed 2 pages.

\section{Introduction}
% 1. As an introduction, include the problem requirements and briefly explain your algorithm.

For the second assignment, assignment B,  it was required to merge two arrays $A$ and $B$. It shall be implement in PThreads and OpenMP. The algorithm is based on the rank operation and should have a time complexity equal to $\O(\log_2(N + M))$, where $N$ and $M$ are the sizes of A and B, respectively. In addition a sequential implementation from which the remaining are inferred should also be given. Both arrays $A$ and $B$ are ordered.

The rank operation, rank($x : X$) returns the number of elements from $X$ smaller than or equal to $x$. Since the input arrays are sorted computing the rank($a : AB$), where $AB$ is the concatenation of A and B, returns the position of value $a$ in the merged array.

To run the ranking operations in parallel we can split each array in subsets ($A_i$ and $B_j$) and merge them independently. This is done in such a way that the resulting merged sequences $C_1, \dots, C_k$ can be simply concatenated to obtain the solution.

The algorithm will be further explained in section~\ref{sec:proof}.

Once again, sequentially this problem is trivial. Simply iterate over $A$ and $B$, select the minimum value from both and iterate the respective index ($i$ for $A$ and $j$ for $B$). Then, assign this value to $C$, the merged array and iterate the appropriate index, $k$.

\section{Algorithm Proof}
\label{sec:proof}
% 2. Give an algorithm proof: show why the algorithm will give the desired results.
% For example, if the exercise is: calculate n!, and your algorithm is: fac(0)=1 and fac(n)=n · fac(n − 1) you should include a proof by induction.


The parallelized algorithm should have a time complexity of $\O(\log_2(N + M))$. In order to obtain it\footnote{This algorithm is based on lecture number 5 from Parallel Parallel Algorithms and
Parallel Computers} we will divide the array $A$ in $\log_2(N)$ subsets and $B$ in $\log_2(M)$ subsets. Thereafter each set will be merged with the other concurrently. Parallel Algorithms and
Parallel Computers. Finally all are concatenated.

Intuitively one can infer this algorithm is correct. Since we consider all the values and they are ordered, at the end we will obtain the expect result.

The pseudocode for this algorithm is show in Algorithm~\ref{alg:merge}. The auxiliary function seqmerge($i,j$) sequentially merges (using balanced tree) $A[i+1,i+2,\dots]$ and $B [j+1,j+2,\dots]$ into $C[i+j+j, i+j+2,\dots]$ until it encounters an index for which a value for $C$ has already been assigned.


\begin{algorithm}[ht]
\caption{Merge ordered arrays $A$ and $B$ to $C$}
\label{alg:merge}
\begin{algorithmic}[1]
	\STATE $a \leftarrow \log_2(n)$; $b \leftarrow \log_2(m)$; $AA[0] \leftarrow 0$;

	\renewcommand{\algorithmicdo}{\textbf{pardo}}
	\FOR{ $i \leftarrow 1$ \TO $n/a$, $j \leftarrow 1$ \TO $m/b$}
		\STATE $AA[i] \leftarrow \text{rank}(A[i \times a] - 1, B)$;
		\STATE $BB[j] \leftarrow \text{rank}(B[j \times b], A )$;
	\ENDFOR

	\FOR{ $i \leftarrow 1$ \TO $n/a$, $j \leftarrow 1$ \TO $m/b$}
		\STATE $C[ AA[i] + a \times i ] \leftarrow A[ a \times i ]$;
		\STATE $C[ BB[i] + b \times i ] \leftarrow B[ b \times i ]$;
	\ENDFOR


	\FOR{ $i \leftarrow 1$ \TO $n/a$, $j \leftarrow 1$ \TO $m/b$}
		\STATE $\text{seqmerge}(i\cdot a , AA[i])$;
		\STATE $\text{seqmerge}(BB[j], j \cdot b)$;
	\ENDFOR
	
\end{algorithmic}
\end{algorithm}

\section{Time-Complexity Analysis}
% 3. Give an analysis of the time-complexity of your algorithm related to the size of the problem (usually N ).

The algorithm shown has three distinct steps that are executed concurrently.
The first performs the rank operations and has a time complexity of $\O(\log_2(N + M))$ since each block has $\O(\log_2{ n+m})$ elements.

The seconds assigns the `border' values to $C$ based on the previously computed rank values. These values will be later be checked by seqmerge. The time complexity of this step is the same as the first.

Finally the results are merged together in $\O(\log_2 ((n+m)/\log_2(n+m)))$.

Therefore the total time complexity is $\O(\log_2{ n+m})$, as intended.

\section{Implementation}
% 4. Implement first a sequential algorithm. Next, add not more than 3 OpenMP pragmas to parallelize the time consuming sections/loops of the code. Further,
% implement the algorithm using PThreads. Explain the transition from pseudocode (or algorithm) to the implementation, focusing especially on work and data distribution.

Both implementations closely mimics the pseudocode shown in Algorithm~\ref{alg:merge}.
Three pgramas were used to schedule the three loops. The chunk is the ratio between the maximum input size and the number of available threads. In addition a pragma to initialize the parallel area was also set, through which the number of threads was specified.

Pthreads is very similar to the just described OpenMP implementation. This time the threads are spawn by the main and synchronize (through a barrier) after the second step, since the next may need values computed by other threads.

The threads are joined after the algorithm finishes.

\section{Results}
\label{sec:results}
% 5. Test your program varying both the problem size (at least 7 different problem
% sizes) and the number of threads (at least 1, 2, 4, 8, and 16 threads - P ). Measure
% the execution time, T , for each of the test cases (be sure to run the application
% multiple times - i.e. 10, 100, or even 1000 times, and average the results).

% Present your results in the following graphs: T (N, P fixed), T (P, N fixed), Speed-up(N, P
% Fixed), Speed-up(P, N fixed). Analyze the results, focusing on the difference (if
% any) between the measured and expected performance. See some more guidelines
% and requirements in subsection 1.5.

The program was tested with the example inputs from the lab manual and the results are summarized in table~\ref{tbl:results}. The machine used was the one provided by the course and was accessed remotely via ssh.

\begin{table}[H]
\centering
\begin{tabular}{lcccccccc}
         & NSize & Iterations & Seq      & Th01      & Th02      & Th04      & Th08      & Th16
\\\midrule
Pthreads	&  32 &     1000 & 0.001347 &  0.049287 &  0.076389 &  0.136729 &  0.758988 &  1.527234\\
OpenMP		&  32 &     1000 & 0.001391 &  0.009754 &  0.012192 &  0.022821 &  0.021166 &  0.024526
\end{tabular}
\caption{Timing results for the Parallel Implementations}
\label{tbl:results}
\end{table}

From table~\ref{tbl:results} it is perceptible that given the current input, the threaded implementations offer no advantage over the sequential one. Each thread should be assigned more work in order to compensate for the communication overhead. Added to this the Pthreads implementation is significantly slower than OpenMP. A possible, and most obvious, explanation is that PThreads is not implemented in the most efficient manner. Regardless, OpenMP is still much slower than the sequential versions.

\section{Conclusions}
% 6. Include a Conclusions section to briefly explain what have you done and, more
% important, what have you learned from the given exercise and its parallelization.
% Comment on efficiency and usability of the given implementation language/library
% for the given application and, if possible, generalize.

In this assignment we were asked to write an algorithm to merge two arrays based on the rank operation. For that, a algorithm from the Course lectures was chosen as it fulfilled the time complexity requirements,  $\O(\log_2(N+M))$
From section~\ref{sec:results} one can conclude that for the input size used the communication overhead is much greater than the gains from parallel execution.
